{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ePnPytq6BslA",
    "outputId": "bfeb9df1-e70e-4baf-e21b-8b64943c4e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.4.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bteOuY9_B76r"
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "import pickle \n",
    "trainers=open('/content/traindump.txt','rb')\n",
    "trainlist=pickle.load(trainers)\n",
    "testers=open('/content/testdump.txt','rb')\n",
    "testlist=pickle.load(testers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_BD5HLmCXHQ"
   },
   "outputs": [],
   "source": [
    "#creating training tokens\n",
    "tokens=[]\n",
    "for i in trainlist:\n",
    "  tokens.extend(i.split())\n",
    "for i in testlist:\n",
    "  tokens.extend(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcQPbtTfCyTH"
   },
   "outputs": [],
   "source": [
    "#the training data will have a sequence of words followed by target word. We create sequences here of length 50 and 1 target word.\n",
    "length = 51\n",
    "sentences = []\n",
    "for i in range(length, len(tokens)):\n",
    "  sequences = tokens[i-length:i]\n",
    "  line = ' '.join(sequences)\n",
    "  sentences.append(line)\n",
    "  #print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yZaoPXxRDwUN",
    "outputId": "f471feb2-b5b1-47e8-d6c5-5fbc51c69cb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hSjiBRiFpjE"
   },
   "outputs": [],
   "source": [
    "#Class for vectorizing texts, or/and turning texts into sequences (=list of word indexes, where the word of rank i in the dataset (starting at 1) has index i).\n",
    "tokenizer=keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZunsoEsYGthz"
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1x20xK_jFwmE"
   },
   "outputs": [],
   "source": [
    "##creates a sort of word to index mapping. Then maps back the words to sequence indexes\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sentences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VvX1a6-xFyuE"
   },
   "outputs": [],
   "source": [
    "#0 is reserved for padding. So we need to add 1 for the embedding to map from 1 to vocab_size.\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5n0A1PxTHFt1"
   },
   "outputs": [],
   "source": [
    "#creating the input sequence and the target word.\n",
    "from numpy import array\n",
    "from keras.utils import to_categorical\n",
    "sentences = array(sentences)\n",
    "X, y = sentences[:,:-1], sentences[:,-1]  # X is input sequences of words, y is target word\n",
    "y = to_categorical(y, num_classes=vocab_size) #allocate index to word \n",
    "sent_length = X.shape[1]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "ECLlH5zeHJTh",
    "outputId": "3a93fc68-c423-432c-e98a-77e3c056b7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 50)            303500    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6070)              613070    \n",
      "=================================================================\n",
      "Total params: 1,067,470\n",
      "Trainable params: 1,067,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#creating the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=sent_length))  \n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "GNdBHXhyHY6L",
    "outputId": "431834c2-51e0-4b6c-d78e-d4f5efaeedf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197725/197725 [==============================] - 334s 2ms/step - loss: 5.3409 - acc: 0.1795\n",
      "Epoch 2/20\n",
      "197725/197725 [==============================] - 329s 2ms/step - loss: 4.7463 - acc: 0.2302\n",
      "Epoch 3/20\n",
      "197725/197725 [==============================] - 330s 2ms/step - loss: 4.4963 - acc: 0.2499\n",
      "Epoch 4/20\n",
      "197725/197725 [==============================] - 330s 2ms/step - loss: 4.3298 - acc: 0.2589\n",
      "Epoch 5/20\n",
      "197725/197725 [==============================] - 330s 2ms/step - loss: 4.2076 - acc: 0.2659\n",
      "Epoch 6/20\n",
      "197725/197725 [==============================] - 332s 2ms/step - loss: 4.1084 - acc: 0.2704\n",
      "Epoch 7/20\n",
      "197725/197725 [==============================] - 329s 2ms/step - loss: 4.0265 - acc: 0.2740\n",
      "Epoch 8/20\n",
      "197725/197725 [==============================] - 328s 2ms/step - loss: 3.9537 - acc: 0.2783\n",
      "Epoch 9/20\n",
      "197725/197725 [==============================] - 328s 2ms/step - loss: 3.9051 - acc: 0.2811\n",
      "Epoch 10/20\n",
      "197725/197725 [==============================] - 331s 2ms/step - loss: 3.8554 - acc: 0.2841\n",
      "Epoch 11/20\n",
      "197725/197725 [==============================] - 333s 2ms/step - loss: 3.8064 - acc: 0.2865\n",
      "Epoch 12/20\n",
      "197725/197725 [==============================] - 332s 2ms/step - loss: 3.7484 - acc: 0.2906\n",
      "Epoch 13/20\n",
      "197725/197725 [==============================] - 329s 2ms/step - loss: 3.6955 - acc: 0.2946\n",
      "Epoch 14/20\n",
      "197725/197725 [==============================] - 329s 2ms/step - loss: 3.6462 - acc: 0.2981\n",
      "Epoch 15/20\n",
      "197725/197725 [==============================] - 330s 2ms/step - loss: 3.6095 - acc: 0.3006\n",
      "Epoch 16/20\n",
      "197725/197725 [==============================] - 333s 2ms/step - loss: 3.5604 - acc: 0.3048\n",
      "Epoch 17/20\n",
      "197725/197725 [==============================] - 333s 2ms/step - loss: 3.5167 - acc: 0.3081\n",
      "Epoch 18/20\n",
      "197725/197725 [==============================] - 329s 2ms/step - loss: 3.4806 - acc: 0.3118\n",
      "Epoch 19/20\n",
      "197725/197725 [==============================] - 329s 2ms/step - loss: 3.4494 - acc: 0.3153\n",
      "Epoch 20/20\n",
      "197725/197725 [==============================] - 328s 2ms/step - loss: 3.4211 - acc: 0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3affbbe10>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #categorical crossentropy as there are multiple classes of words to predict\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6J-DlqhOt0eT"
   },
   "outputs": [],
   "source": [
    "#function for generating output\n",
    "def create_output(model, tokenizer, seqlength, seed, number_words):\n",
    "\tgen = []\n",
    "\ttext_input = seed\n",
    "\tfor i in range(number_words):\n",
    "\t\tencoded = tokenizer.texts_to_sequences([text_input])[0]\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seqlength, truncating='pre')\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\toutput = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\toutput = word\n",
    "\t\t\t\tbreak\n",
    "\t\ttext_input += ' ' + output\n",
    "\t\tgen.append(output)\n",
    "\treturn ' '.join(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrSnfWx-t3FS"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymNiq5ept8HM"
   },
   "outputs": [],
   "source": [
    "length = 51\n",
    "sent = []\n",
    "for i in range(length, len(tokens)):\n",
    "  sequences = tokens[i-length:i]\n",
    "  line = ' '.join(sequences)\n",
    "  sent.append(line)\n",
    "  #print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BO_nhkjZIgn7"
   },
   "outputs": [],
   "source": [
    "#omitting 1 word for prediction task\n",
    "seqlength = len(sent[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJq6yUX9IhL9"
   },
   "outputs": [],
   "source": [
    "#selecting random sentence for prediction\n",
    "from random import randint\n",
    "seed = sent[randint(0,len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gjf84fNaIiqV",
    "outputId": "86c41648-7711-4644-bd57-da1b69676fec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have to do s s we have to do it s s\n"
     ]
    }
   ],
   "source": [
    "output_sentences = create_output(model, tokenizer,seqlength, seed, 12)\n",
    "print(output_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oroJQBWHIvVO"
   },
   "outputs": [],
   "source": [
    "#We can see that as compared to RNNs, the output is coherent here also. It is also more coherent than ngrams as LSTMs can learn long term context much better than both RNNs and ngrams owing to the additional gates which they employ. HEre, due to lesser number of epochs, the output is not very good. Increasing the number of epochs will surely solve this issue."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTMs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
